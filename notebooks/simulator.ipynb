{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simpy\n",
    "import numpy as np\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTAINER_PROFILE_DIRECTORY = {\n",
    "    \"S\" : 1,\n",
    "    \"M\" : 2,\n",
    "    \"L\" : 4,\n",
    "    \"XL\": 8,\n",
    "}\n",
    "\n",
    "CONTAINER_DESTRUCTION_OVHERHEAD = 1\n",
    "CONTAINER_CREATION_OVERHEAD = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Datacenter(object):\n",
    "    \"\"\"Encapsualtes a cluster, its cluster monitor, and job scheduler\"\"\"\n",
    "    \n",
    "    def __init__(self, env, n_pms, pm_resources, job_profiles, weights):\n",
    "        self.env = env\n",
    "        self.n_pms = n_pms\n",
    "        self.pm_resources = pm_resources\n",
    "        self.job_profiles = job_profiles\n",
    "        self.weights = weights\n",
    "        \n",
    "    def state_vector(self):\n",
    "        return np.hstack([self.cluster.vectorize(), self.job_queue.vectorize()])\n",
    "    \n",
    "    def action(self, index):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cluster(object):\n",
    "    def __init__(self, env, N, pm_capacity, job_generator):\n",
    "        self.total_resources = N*pm_capacity\n",
    "        labels = (\"pm-\" + str(i) for i in range(N))\n",
    "        self.physical_machines = {label: PhysicalMachine(env, pm_capacity) for label in labels}\n",
    "        self.job_generator = job_generator\n",
    "        \n",
    "    def resource_utilization(self):\n",
    "        resources_utilized = sum(pm.utilized_resources.level for pm in self.physical_machines.values())\n",
    "        return resources_utilized/self.total_resources\n",
    "    \n",
    "    def schedule_job(self, job_index, pm, container_profile):\n",
    "        job = self.job_generator.job_queue.buffer[job_index]\n",
    "        pm = self.physical_machines[pm]\n",
    "        yield env.process(pm.schedule_job(job, container_profile))\n",
    "        self.job_generator.enqueue_job(job_index)\n",
    "        \n",
    "    def vectorize(self):\n",
    "        return np.hstack([pm.vectorize() for pm in self.physical_machines.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JobProfile(object):\n",
    "    def __init__(self, resources, time):\n",
    "        self.resources = resources\n",
    "        self.time = time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JobQueue(object):\n",
    "    def __init__(self, env, buffer_size):\n",
    "        self.buffer_size = buffer_size\n",
    "        self.buffer = [None]*buffer_size\n",
    "        \n",
    "    def vectorize(self):\n",
    "        job_profile_vectors = np.array([job.vectorize() for job in self.buffer])\n",
    "        return np.hstack(job_profile_vectors)\n",
    "\n",
    "        \n",
    "class JobGenerator(object):\n",
    "    \"\"\" creates jobs and places them on a job queue\"\"\"\n",
    "    def __init__(self, env, job_queue_size, job_profiles, weights, log):\n",
    "        self.env = env\n",
    "        self.job_profiles = job_profiles\n",
    "        self.weights = weights\n",
    "        self.job_queue_size = job_queue_size\n",
    "        self.job_queue = JobQueue(env, job_queue_size)\n",
    "        self.log = log\n",
    "        for i in range(job_queue_size):\n",
    "            self.job_queue.buffer[i] = self.generate_job()\n",
    "        \n",
    "    \n",
    "    def generate_job(self):\n",
    "        job_profile = np.random.choice(self.job_profiles, p=self.weights)\n",
    "        job = Job(job_profile.resources, job_profile.time, self.log)\n",
    "    \n",
    "    def enqueue_job(self, job_index):\n",
    "        new_job = self.generate_job()\n",
    "        new_job.enqueue()\n",
    "        self.job_queue.buffer[job_index] = new_job\n",
    "\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Log(simpy.Store):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Job(object):\n",
    "    \n",
    "    def __init__(self, resources, time, log):\n",
    "        self.resources = resources\n",
    "        self.time = time\n",
    "        self.log = log\n",
    "    \n",
    "    def enqueue(self):\n",
    "        self.start = self.env.now\n",
    "    \n",
    "    def execute(self):\n",
    "        delay = self.env.now - self.start\n",
    "        job_slowdown = (delay + self.time)/self.time\n",
    "        self.log.put(job_slowdown)\n",
    "        \n",
    "    def vectorize(self):\n",
    "        return np.array([self.resource, self.time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhysicalMachine(object):\n",
    "    \n",
    "    def __init__(self, env, total_resource_capacity):\n",
    "        self.env = env\n",
    "        self.total_resources = total_resource_capacity\n",
    "        self.available_resources = simpy.Container(env, capacity=total_resource_capacity, init=total_resource_capacity)\n",
    "        self.containers = {}\n",
    "        for container_label, resource_requirement in CONTAINER_PROFILE_DIRECTORY.items():\n",
    "            max_containers = total_resource_capacity//resource_requirement\n",
    "            self.containers[container_label] = simpy.Container(env, capacity=max_containers, init=0) \n",
    "            \n",
    "        # utilized resources is only incremented when a machine esecutes a job\n",
    "        self.utilized_resources = simpy.Container(env, capacity=total_resource_capacity, init=0)\n",
    "        #fill machine randomly with VMs\n",
    "        \n",
    "    def add_container(self, profile):\n",
    "        print(\"adding container\")\n",
    "        resources_requested = CONTAINER_PROFILE_DIRECTORY[profile]\n",
    "        if resources_requested < self.available_resources.level:\n",
    "            self.available_resources.get(resources_requested)\n",
    "            yield self.env.timeout(CONTAINER_CREATION_OVERHEAD)\n",
    "            self.containers[profile].put(1)\n",
    "        else:\n",
    "            print(\"not enough resources\")\n",
    "\n",
    "    \n",
    "    def destroy_container(self, profile):\n",
    "        if self.containers[profile].level > 0:\n",
    "            print(\"destroying container\")\n",
    "            resources_to_free = CONTAINER_PROFILE_DIRECTORY[profile]\n",
    "            yield self.env.timeout(CONTAINER_DESTRUCTION_OVHERHEAD)\n",
    "            self.containers[profile].get(1)\n",
    "            self.available_resources.put(resources_to_free)\n",
    "        else:\n",
    "            print(\"no container available\")\n",
    "            \n",
    "            \n",
    "    def schedule_job(self, job, container_profile):\n",
    "        if self.containers[container_profile].level > 0:\n",
    "            print(\"scheduling job\")\n",
    "            self.containers[container_profile].get(1)\n",
    "            self.utilized_resources.put(job.resources)\n",
    "            yield self.env.timeout(job.time)\n",
    "            job.execute()\n",
    "            print(\"completing job\")\n",
    "            self.containers[container_profile].put(1)\n",
    "            self.utilized_resources.get(job.resources)\n",
    "        else:\n",
    "            print(\"no available machines\")\n",
    "            \n",
    "    def vectorize(self):\n",
    "        levels = [container.level for container in self.containers.values()]\n",
    "        return np.array(levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def resource_utilization_monitor(env, cluster, interval=10):\n",
    "#     while True:\n",
    "#         yield env.timeout(interval)\n",
    "#         print(env.now, cluster.resource_utilization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusterMonitor(object):\n",
    "    def __init__(self, env, cluster):\n",
    "        self.env = env\n",
    "        self.cluster = cluster\n",
    "        env.process(self.monitor_resource_utilization())\n",
    "        env.process(self.monitor_job_slowdown())\n",
    "        \n",
    "    def monitor_resource_utilization(self, interval=10):\n",
    "        self.resource_utilization = 0\n",
    "        while True:\n",
    "            yield env.timeout(interval)\n",
    "            self.resource_utilization = cluster.resource_utilization()\n",
    "            print(env.now, self.get_resource_utilization(), self.get_average_job_slowdown())\n",
    "    \n",
    "    def monitor_job_slowdown(self, window=10):\n",
    "        self.job_reports = simpy.Store(env)\n",
    "        self.job_records = deque(maxlen=window)\n",
    "        self.total_jobs = 0\n",
    "        self.average_job_slowdown = 1.0\n",
    "        while True:\n",
    "            job_slowdown = yield self.job_reports.get()\n",
    "            self.job_records.append(job_slowdown)\n",
    "            \n",
    "    def get_resource_utilization(self):\n",
    "        return self.cluster.resource_utilization()\n",
    "    \n",
    "    def get_average_job_slowdown(self):\n",
    "        return np.average(self.job_records)\n",
    "    \n",
    "    def vectorize(self):\n",
    "        return np.array([self.get_resource_utilizaiton(), self.get_average_job_slowdown()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(env, cluster, cm, jq):\n",
    "    pm = cluster.physical_machines['pm-1']\n",
    "    yield env.timeout(1)\n",
    "    env.process(pm.add_container('S'))\n",
    "    yield env.timeout(1)\n",
    "    env.process(pm.add_container('XL'))\n",
    "    j1 = Job(5,95, jq)\n",
    "    j2 = Job(1,45, jq)\n",
    "    yield env.timeout(25)\n",
    "    \n",
    "    env.process(cluster.schedule_job(j1, 'pm-1', 'XL'))\n",
    "    yield env.timeout(35)\n",
    "    env.process(cluster.schedule_job(j2, 'pm-1', 'S'))\n",
    "    yield env.timeout(100)\n",
    "    env.process(pm.destroy_container('XL'))\n",
    "    yield env.timeout(10)\n",
    "    env.process(pm.destroy_container('S'))\n",
    "    yield env.timeout(100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# env = simpy.Environment()\n",
    "# log = Log(env)\n",
    "# SIM_DURATION = 300\n",
    "# cluster = Cluster(env, 2, 32)\n",
    "# cluster_monitor = ClusterMonitor(env, cluster)\n",
    "# env.process(test(env, cluster, cluster_monitor, log))\n",
    "# env.run(until=SIM_DURATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = simpy.Environment()\n",
    "\n",
    "\n",
    "log = Log(env)\n",
    "SIM_DURATION = 300\n",
    "\n",
    "\n",
    "jp = JobProfile(3, 12)\n",
    "job_generator = JobGenerator(env, 16, [jp], [1.0], log)\n",
    "cluster = Cluster(env, 2, 32, job_generator)\n",
    "cluster_monitor = ClusterMonitor(env, cluster)\n",
    "\n",
    "\n",
    "def test(env, cluster, cluster_monitor, job_generator, log):\n",
    "    env.process(pm.add_container('S'))\n",
    "    env.process(pm.add_container('M'))\n",
    "    env.process(pm.add_container('L'))\n",
    "    env.process(pm.add_container('XL'))\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
